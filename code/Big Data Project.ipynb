{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from random import sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import wordcloud\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../input/covid19-in-india/covid_19_india.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understand the data\n",
    "data = pd.DataFrame(data)\n",
    "data.shape\n",
    "data.columns\n",
    "len(data.ConfirmedIndianNational)\n",
    "len(data.Deaths)\n",
    "len(data.Cured)\n",
    "len(data.Date)\n",
    "data.info()\n",
    "data.describe()\n",
    "data['ConfirmedIndianNational'].describe()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed we can also replace the name of column\n",
    "data = data.rename(columns = {\"State/UnionTerritory\":\"State\",\n",
    "                              \"ConfirmedIndianNational\":\"Confirmed_Indian\",\n",
    "                              \"ConfirmedForeignNational\":\"Confirmed_Foreginer\",\n",
    "                              \"Cured\":\"Recovered\"})\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the SNo or column\n",
    "#ab = data.ix[:,1:]  Another method for droppping column\n",
    "df = data.drop(['Sno','Time'],1)\n",
    "df.columns\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst = True)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "#df['Confirmed_Total'] = df['Confirmed_Indian']+df['Confirmed_Foreginer']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values checkup\n",
    "df.isna().sum()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.columns\n",
    "df['State'] = df['State'].replace(\"Uttar Pradesh\", \"Uttar_Pradesh\")\n",
    "df['State'] = df['State'].replace(\"Andaman and Nicobar Islands\", \"Andaman_and_Nicobar_Islands\")\n",
    "df['State'] = df['State'].replace(\"Andhra Pradesh\", \"Andhra_Pradesh\")\n",
    "df['State'] = df['State'].replace(\"Himachal Pradesh\", \"Himachal_Pradesh\")\n",
    "df['State'] = df['State'].replace(\"Jammu and Kashmir\", \"Jammu_and_Kashmir\")\n",
    "df['State'] = df['State'].replace(\"Madhya Pradesh\", \"Madhya_Pradesh\")\n",
    "df['State'] = df['State'].replace(\"Tamil Nadu\", \"Tamil_Nadu\")\n",
    "df['State'] = df['State'].replace(\"West Bengal\", \"West_Bengal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day=df.groupby('Date')['Confirmed_Indian','Confirmed_Foreginer','Confirmed',\n",
    "          'Deaths', 'Recovered'].sum()\n",
    "df_per_day1=df.groupby('Date')['Confirmed_Indian','Confirmed_Foreginer','Confirmed',\n",
    "          'Deaths', 'Recovered'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximum number of cases\n",
    "df_per_day['Confirmed'].max() \n",
    "df_per_day1['Confirmed'].max()\n",
    "\n",
    "#minimum number of cases\n",
    "df_per_day['Confirmed'].min()\n",
    "\n",
    "#which day has max cases\n",
    "df_per_day['Confirmed'].idxmax()\n",
    "\n",
    "#which day has minimum cases\n",
    "df_per_day['Confirmed'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No of cases per country State\n",
    "\n",
    "df.groupby(['State'])['Confirmed_Indian','Confirmed_Foreginer','Confirmed',\n",
    "          'Deaths', 'Recovered'].max()\n",
    "#no of cases per country by descending order\n",
    "a=df.groupby(['State'])['Confirmed_Indian','Confirmed_Foreginer','Confirmed','Deaths', 'Recovered'].max().sort_values(by = 'Confirmed', ascending= False)\n",
    "\n",
    "#how many countried affected\n",
    "States = df['State'].unique()\n",
    "len(df['State'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud for Confirmed cases in Country\n",
    "State = str(a.Confirmed)\n",
    "cloud = WordCloud(max_words=70,background_color=\"white\").generate(State)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(cloud, interpolation='Bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COVID-19 ######## Symptoms Anlaysis\n",
    "\n",
    "symptoms={'symptom':['Fever','Dry cough','Fatigue','Sputum production',\n",
    "                     'Loss of smell','Shortness of breath','Muscle pain or Joint pain',\n",
    "                     'Sore throat','Headache','Chills','Nausea or vomiting',\n",
    "                     'Nasal congestion','Diarrhoea','Haemoptysis','Conjunctival congestion']\n",
    ",'percentage':[87.9,67.7,38.1,33.4,15,18.6,14.8,13.9,13.6,11.4,5.0,4.8,3.7,0.9,0.8]}\n",
    "\n",
    "con_symptoms=pd.DataFrame(data=symptoms)\n",
    "con_symptoms\n",
    "\n",
    "# Graph for Symptoms and Percentage\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(con_symptoms['symptom'],con_symptoms['percentage'], color = 'm')\n",
    "plt.legend()\n",
    "plt.title('Conditions of Covid-19')\n",
    "plt.xlabel('Symptoms')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Pie plot for symptoms\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Symptoms of Coronavirus',fontsize=20) \n",
    "plt.pie(con_symptoms['percentage'],autopct='%1.1f%%')\n",
    "plt.legend(symptoms['symptom'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph for Cases observed per day\n",
    "\n",
    "b = df.groupby(['Date'])['Recovered','Deaths','Confirmed',].sum().sort_values(by = 'Date', ascending = True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(b['Confirmed'],'bo', label = 'Confirmed_Total', linewidth = 2, linestyle = ':')\n",
    "plt.plot(b['Deaths'],'ro', label = 'Deaths',linewidth = 2, linestyle = '--',)\n",
    "plt.plot(b['Recovered'],'go', label = 'Recovered',linewidth = 2,linestyle = '-.')\n",
    "plt.title('Cases per day')\n",
    "plt.xlabel('Dates')\n",
    "#plt.xticks([0,9,19,29])\n",
    "plt.ylabel('Cases')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases observed per state\n",
    "import seaborn as sns\n",
    "c=df.groupby(['State'])['Confirmed','Deaths', 'Recovered'].max().sort_values(by = 'Confirmed', ascending= False)\n",
    "\n",
    "c.head(45).plot.bar(color = ('m','r','g'), figsize = (10,10), width = 0.9)\n",
    "plt.title('Cases per State')\n",
    "plt.xlabel('States in India')\n",
    "plt.ylabel('Cases', labelpad = 20)\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "#Cases in State in Stacked form\n",
    "c.head(45).plot.bar(stacked = True, color = ('m','r','g'), figsize = (20,10))\n",
    "plt.title('Cases per State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Cases')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make another group for adding calculated columns\n",
    "c = df.groupby(['State'])['Confirmed','Deaths', 'Recovered'].max().sort_values(by = 'Confirmed', ascending= False)\n",
    "\n",
    "# percent Death Rate\n",
    "c['Percent_Deaths'] = c['Deaths']/c['Confirmed']*100\n",
    "c['Percent_Deaths']= round(c['Percent_Deaths'], 2)\n",
    "\n",
    "#Death rate state wise\n",
    "c['Percent_Deaths'].sort_values().head(55).plot.bar(figsize = (10,10), color = 'r')\n",
    "plt.title('Death Rate')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Percent Death Rate')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent Recoverey rate\n",
    "c['Percent_Recovery']=c['Recovered']/c['Confirmed']*100\n",
    "c['Percent_Recovery'] = round(c['Percent_Recovery'], 2)\n",
    "\n",
    "# Percent recovery rate Country wise\n",
    "c['Percent_Recovery'].sort_values().tail(55).plot.bar(figsize = (10,10), color = 'g')\n",
    "plt.title('Recovery Rate')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Percent Recovery Rate')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked plot for Recovery rate and Death rate\n",
    "c[['Percent_Deaths', 'Percent_Recovery']].sort_values(by = 'Percent_Recovery', ascending = False).plot.bar(stacked = True, figsize = (10,10), color = ('r','g'))\n",
    "\n",
    "c[['Percent_Deaths', 'Percent_Recovery']].sort_values(by = 'Percent_Deaths', ascending = False).plot.bar(stacked = True, figsize = (10,10), color = ('r','g'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Cases in each state\n",
    "c['Active'] = c['Confirmed']-c['Deaths']-c['Recovered']\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.pie(c['Active'], labels = c['Active'])\n",
    "plt.legend(c.index, loc = 'best', fontsize = 8)\n",
    "plt.title('Active Corona Cases in India')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent recovery and Percent Death rate Date wise in scatter plot\n",
    "d = df.groupby(['Date'])['Confirmed','Deaths', 'Recovered'].sum().sort_values(by  ='Date',ascending= True)\n",
    "# Active Cases in India Date Wise\n",
    "d['Active'] = d['Confirmed']-d['Deaths']-d['Recovered']\n",
    "\n",
    "d['Percent_Deaths'] = d['Deaths']/d['Confirmed']*100\n",
    "d['Percent_Deaths']= round(d['Percent_Deaths'], 2)\n",
    "d['Percent_Recovery']=d['Recovered']/d['Confirmed']*100\n",
    "d['Percent_Recovery'] = round(d['Percent_Recovery'], 2)\n",
    "d['Percent_Active']=d['Active']/d['Confirmed']*100\n",
    "d['Percent_Active'] = round(d['Percent_Active'], 2)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(d['Percent_Recovery'], 'b', label = 'Percent_Recovery')\n",
    "plt.plot(d['Percent_Deaths'], 'r', label = 'Percent_Deaths')\n",
    "plt.plot(d['Percent_Active'],'y',label = 'Percent_Active')\n",
    "plt.title('Recovery Rate Vs Death Rate Vs Active Rate')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percencent Rate')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "# Datewise growth Rate\n",
    "g = df.groupby(['Date'])['Confirmed','Deaths', 'Recovered'].sum().sort_values(by = 'Date', ascending = True)\n",
    "print(g.iloc[-1])\n",
    "\n",
    "increased_Confirmed=[]\n",
    "increased_Recovered=[]\n",
    "increased_Deaths=[]\n",
    "z = 0\n",
    "for z in range(g.shape[0]-1):\n",
    "    increased_Confirmed.append(((g['Confirmed'].iloc[z+1])/g['Confirmed'].iloc[z]))\n",
    "    increased_Recovered.append(((g['Recovered'].iloc[z+1])/g['Recovered'].iloc[z]))\n",
    "    increased_Deaths.append(((g['Deaths'].iloc[z+1])/g['Deaths'].iloc[z]))\n",
    "increased_Confirmed.insert(0,1)\n",
    "increased_Recovered.insert(0,1)\n",
    "increased_Deaths.insert(0,1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(g.index,increased_Confirmed,'bo',label=\"Growth Rate of Confirmed Cases\",linestyle = ':')\n",
    "plt.plot(g.index,increased_Recovered,'go',label=\"Growth Rate of Recovered Cases\",linestyle = '-.')\n",
    "plt.plot(g.index,increased_Deaths,'ro',label=\"Growth Rate of Death Cases\",linestyle = '--')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Datewise Growth Rate of different Types of Cases\")\n",
    "plt.ylabel(\"Growth Rate\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.legend()\n",
    "\n",
    "# Daily increase in Case\n",
    "g = df.groupby(['Date'])['Confirmed','Deaths', 'Recovered'].sum().sort_values(by = 'Date', ascending = True)\n",
    "\n",
    "ts=g.reset_index().sort_values('Date')\n",
    "Confirmed=ts.Confirmed\n",
    "Deaths=ts.Deaths\n",
    "Recovered=ts.Recovered\n",
    "New_Confirmed=[Confirmed[0]]\n",
    "New_Deaths=[Deaths[0]]\n",
    "New_Recovered=[Recovered[0]]\n",
    "for i in range(1,len(Confirmed)):\n",
    "    New_Confirmed.append(Confirmed[i]-Confirmed[i-1])\n",
    "    New_Deaths.append(Deaths[i]-Deaths[i-1])\n",
    "    New_Recovered.append(Recovered[i]-Recovered[i-1])\n",
    "ts['New_Confirmed']=New_Confirmed\n",
    "ts['New_Deaths']=New_Deaths\n",
    "ts['New_Recovered']=New_Recovered\n",
    "ts.head()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(ts['Date'],ts['New_Confirmed'],'bo',label=\"New Confirmed Cases\", linestyle = ':')\n",
    "plt.plot(ts['Date'],ts['New_Recovered'],'go',label=\"New Recovered Cases\",linestyle = '-.')\n",
    "plt.plot(ts['Date'],ts['New_Deaths'],'ro',label=\"New Death Cases\",linestyle = '--')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"New Cases added each day\")\n",
    "plt.ylabel(\"Cases\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date Time\n",
    "from datetime import date\n",
    "e = df.copy()\n",
    "e = e.drop(['State','Confirmed_Indian','Confirmed_Foreginer'],1)\n",
    "e =e.groupby('Date').sum().reset_index()\n",
    "i = 0\n",
    "e['Days'] = 1\n",
    "#####RUN THIS ONLY ONE TIME #################\n",
    "for ind in e.index: \n",
    "    e['Days'][ind] = i\n",
    "    i=i+1\n",
    "#############################################\n",
    "\n",
    "# Select only required variables and make new data frame\n",
    "f = e.ix[:,(3,4)]\n",
    "f.head(3)\n",
    "\n",
    "#taking value into two variables X and y\n",
    "X = f.ix[:,1] # Predictor # No of Days\n",
    "X.head(3)\n",
    "X_matrix = X.values.reshape(-1,1)\n",
    "y = f.ix[:,0] # Response Variable # Total Confirmed Cases\n",
    "y.head(3)\n",
    "\n",
    "\n",
    "# splitting of training and testing data\n",
    "X_matrix_train,X_matrix_test,y_train,y_test = train_test_split(X_matrix,y, test_size = 0.15,shuffle=False)\n",
    "len(X_matrix_train)\n",
    "len(X_matrix_test)\n",
    "len(y_train)\n",
    "len(y_test)\n",
    "\n",
    "X_matrix_train.shape\n",
    "X_matrix_test.shape\n",
    "y_train.shape\n",
    "y_test.shape\n",
    "\n",
    "# New data created for prediction\n",
    "new_data=pd.DataFrame(data=[0,60,70,80,90,100,110,120,130,140,150],columns=['Days'])\n",
    "new_data\n",
    "new_data_matrix = new_data.values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# LINEAR REGRESSION MODEL####################\n",
    "\n",
    "# Library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Actual Model with Confirmed cases and no of Days\n",
    "linear_model = LinearRegression(normalize=True, fit_intercept=True)\n",
    "linear_model.fit(X_matrix_train, y_train)\n",
    "linear_model.score(X_matrix_train,y_train)\n",
    "print(linear_model.intercept_)\n",
    "print(linear_model.coef_)\n",
    "\n",
    "###--Training Accuracy ---############\n",
    "pred_y=linear_model.predict(X_matrix_train)\n",
    "pred_y\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print('MAE Training set:', mean_absolute_error(pred_y, y_train))\n",
    "print('MSE Training set:',mean_squared_error(pred_y, y_train))\n",
    "MSE_tlr = mean_squared_error(pred_y, y_train)\n",
    "print('RMSE Training set:',np.sqrt(MSE_tlr)) \n",
    "\n",
    "######## Testing Accuaracy##########\n",
    "y_pred = linear_model.predict(X_matrix_test)\n",
    "y_pred\n",
    "\n",
    "print('MAE Testing set:', mean_absolute_error(y_pred, y_test))\n",
    "print('MSE Testing set:',mean_squared_error(y_pred, y_test)) \n",
    "MSE_lr = mean_squared_error(y_pred, y_test)\n",
    "print('RMSE Testing set:',np.sqrt(MSE_lr))\n",
    "\n",
    "# Prediction for unknow of future data created with new data matrix\n",
    "linear_pred = linear_model.predict(new_data_matrix) #prediction of future days 60,70,80,90,100\n",
    "linear_pred\n",
    "\n",
    "# Plot for Linear Regression\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(f['Days'], f['Confirmed'])\n",
    "plt.plot(new_data_matrix, linear_pred, linestyle='dashed', color='orange')\n",
    "plt.title('# of Coronavirus Cases Over Time')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('# of Cases', size=30)\n",
    "plt.legend(['Confirmed Cases', 'Linear Regression Predictions'])\n",
    "plt.xticks([0,9,19,29,39,49,59,69,79,89,99,109,119,129,139,149])\n",
    "plt.show()\n",
    "#Linear Regrssion is not good fit for the data \n",
    "########### END END END LINEAR REGRESSION MODEL #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SUPPORT VECTOR MACHINE #########################\n",
    "#Libraries needs to install\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#svm = SVR(kernel='poly')\n",
    "# use this to find the optimal parameters for SVR\n",
    "#c = [0.01, 0.1, 1]\n",
    "#gamma = [0.01, 0.1, 1]\n",
    "#epsilon = [0.01, 0.1, 1]\n",
    "#shrinking = [True, False]\n",
    "#degree = [3, 4, 5]\n",
    "#svm_grid = {'C': c, 'gamma' : gamma, 'epsilon': epsilon, 'shrinking' : shrinking, 'degree': degree}\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#svm_search = RandomizedSearchCV(svm, svm_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=30, verbose=1)\n",
    "#svm_search.fit(X_matrix_train, y_train)\n",
    "#svm_search.best_params_\n",
    "svCT = SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1,degree=6, C=0.1).fit(X_matrix_train, y_train)\n",
    "print(svCT)\n",
    "\n",
    "\n",
    "###--Training Accuracy ---############\n",
    "pred_svm_y=svCT.predict(X_matrix_train)\n",
    "pred_svm_y\n",
    "\n",
    "print('MAE training set:', mean_absolute_error(pred_svm_y, y_train))\n",
    "print('MSE training set:',mean_squared_error(pred_svm_y, y_train))\n",
    "MSE_tsvm = mean_squared_error(pred_svm_y, y_train)\n",
    "print('RMSE training set:',np.sqrt(MSE_tsvm)) \n",
    "\n",
    "######## Testing Accuaracy##########\n",
    "svm_y_pred = svCT.predict(X_matrix_test)\n",
    "svm_y_pred\n",
    "\n",
    "print('MAE testing set:', mean_absolute_error(svm_y_pred, y_test))\n",
    "print('MSE testing set:',mean_squared_error(svm_y_pred, y_test)) \n",
    "MSE_svm = mean_squared_error(svm_y_pred, y_test)\n",
    "print('RMSE testing set:',np.sqrt(MSE_svm))\n",
    "\n",
    "plt.plot(svm_y_pred)\n",
    "plt.plot(y_test)\n",
    "\n",
    "svm_new_data_pred = svCT.predict(new_data_matrix) #prediction of future days 60,70,80,90,100\n",
    "# Plot for SVM predictions\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(f['Days'], f['Confirmed'])\n",
    "plt.plot(new_data_matrix, svm_new_data_pred,'mo', linestyle='dashed')\n",
    "plt.title('Coronavirus Cases Over Time')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Cases', size=30)\n",
    "plt.legend(['Confirmed Cases', 'SVM Predictions'])\n",
    "plt.xticks([0,9,19,29,39,49,59,69,79,89,99,109,119,129,139,149])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "poly_X_matrix_train = poly.fit_transform(X_matrix_train)\n",
    "poly_X_matrix_test = poly.fit_transform(X_matrix_test)\n",
    "poly_new_data_matrix = poly.fit_transform(new_data_matrix)\n",
    "\n",
    "poly_linear_model = LinearRegression(normalize=True, fit_intercept=False)\n",
    "poly_linear_model.fit(poly_X_matrix_train, y_train)\n",
    "\n",
    "###--Training Accuracy ---############\n",
    "pred_poly_y=poly_linear_model.predict(poly_X_matrix_train)\n",
    "pred_poly_y\n",
    "\n",
    "print('MAE training set:', mean_absolute_error(pred_poly_y, y_train))\n",
    "print('MSE training set:',mean_squared_error(pred_poly_y, y_train))\n",
    "MSE_tpr = mean_squared_error(pred_poly_y, y_train)\n",
    "print('RMSE training set:',np.sqrt(MSE_tpr))\n",
    "\n",
    "######## Testing Accuaracy##########\n",
    "poly_y_pred = poly_linear_model.predict(poly_X_matrix_test)\n",
    "poly_y_pred\n",
    "\n",
    "print('MAE testing set:', mean_absolute_error(poly_y_pred, y_test))\n",
    "print('MSE testing set:',mean_squared_error(poly_y_pred, y_test))\n",
    "MSE_pr = mean_squared_error(poly_y_pred, y_test)\n",
    "print('RMSE testing set:',np.sqrt(MSE_pr))\n",
    "\n",
    "plt.plot(poly_y_pred)\n",
    "plt.plot(y_test)\n",
    "\n",
    "poly_new_data_pred = poly_linear_model.predict(poly_new_data_matrix) #prediction of future days 60,70,80,90,100\n",
    "\n",
    "#Plot for poly regression\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(f['Days'], f['Confirmed'])\n",
    "plt.plot(new_data_matrix, poly_new_data_pred, 'mo',linestyle='dashed')\n",
    "plt.title('# of Coronavirus Cases Over Time')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('# of Cases', size=30)\n",
    "plt.legend(['Confirmed Cases', 'Poly Rgression Predictions'])\n",
    "plt.xticks([0,9,19,29,39,49,59,69,79,89,99,109,119,129,139,149])\n",
    "plt.show()\n",
    "############# Polynomial Regression Ends############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "score.append(np.sqrt(MSE_lr))\n",
    "score.append(np.sqrt(MSE_svm))\n",
    "score.append(np.sqrt(MSE_pr))\n",
    "score\n",
    "\n",
    "model_names=[\"Linear Regression\",\"Support Vector Machine Machine\",\"Polynomial Regression\"]\n",
    "final = pd.DataFrame(zip(model_names,score),columns=[\"Model Name\",\"Root Mean Squared Error\"]).sort_values([\"Root Mean Squared Error\"])\n",
    "final\n",
    "\n",
    "#Polynomial Regression is most fit plot the preditction of confimred cases over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
